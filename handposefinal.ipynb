{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": "import cv2\nimport mediapipe as mp\nmp_drawing = mp.solutions.drawing_utils\nmp_hands = mp.solutions.hands"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": "import tensorflow as tf"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": "model = tf.keras.models.load_model(\"signlang_new.h5\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.99794024\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.973177\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.992931\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.99999917\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.99683654\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.9999887\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.9999963\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.99999976\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.9997967\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.9999255\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n"
    }
   ],
   "source": "hands = mp_hands.Hands(\n    min_detection_confidence=0.7, min_tracking_confidence=0.5)\ncap = cv2.VideoCapture(0)\nwhile cap.isOpened():\n  success, image = cap.read()\n  img_cpy=image.copy()\n  roimg=image.copy()\n  img_cpy=cv2.flip(img_cpy, 1)\n  roimg=cv2.flip(roimg, 1)\n  height, width, channels = image.shape\n\n  if not success:\n    break\n\n  # Flip the image horizontally for a later selfie-view display, and convert\n  # the BGR image to RGB.\n  image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n  # To improve performance, optionally mark the image as not writeable to\n  # pass by reference.\n  image.flags.writeable = False\n  results = hands.process(image)\n\n  # Draw the hand annotations on the image.\n  image.flags.writeable = True\n  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n  if results.multi_hand_landmarks:\n    for hand_landmarks in results.multi_hand_landmarks:\n      mp_drawing.draw_landmarks(\n          image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n    \n    for i,v in enumerate(results.multi_hand_landmarks):\n      xcords=[]\n      ycords=[]\n      hand_coords=str(v)\n      hand_coords=hand_coords.split('landmark')\n      hand_coords=hand_coords[1:]\n      for lm in hand_coords:\n        b=lm.split('\\n')\n        x=float(b[1].split(' ')[3])\n        y=float(b[2].split(' ')[3])\n        z=float(b[3].split(' ')[3])\n        xcords.append(x)\n        ycords.append(y)\n      #print(str(x) + \" \" + str(y) + \" \"+ str(z))\n        img_cpy = cv2.circle(img_cpy,(int(x*width),int(y*height)), 2, (255, 0, 0), 2)\n        \n    thumbIsOpen = False;\n    firstFingerIsOpen = False;\n    secondFingerIsOpen = False;\n    thirdFingerIsOpen = False;\n    fourthFingerIsOpen = False;\n        \n        #boundingbox\n    if len(xcords)!=0  and len(ycords)!=0:\n        x_max=max(xcords)\n        x_min=min(xcords)\n        y_max=max(ycords)\n        y_min=min(ycords)\n        \n        img_cpy=cv2.rectangle(img_cpy, (int(x_min*width),int(y_min*height)), (int(x_max*width),int(y_max*height)), (255,0,0), 2)\n        #roi =img_cpy[int(y_min*height):int(y_max*height), int(x_min*width):int(x_max*width)]\n        \n        roi =roimg[int(y_min*height)-(20 if y_min*height-20>0 else 0):int(y_max*height)+(20 if y_max*height+20<height else 0), int(x_min*width)-(20 if x_min*width-20>0 else 0):int(x_max*width)+(20 if x_max*width+20<width else 0)]\n        '''\n        if (roi.shape[0]>0 and roi.shape[1]>0):\n            proc_img=hand = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n            proc_img=cv2.resize(proc_img,(28,28))\n            proc_img = np.expand_dims(proc_img, axis=2)\n            proc_img = np.expand_dims(proc_img, axis=0)\n            predclass=model.predict_classes(proc_img)[0]\n            if (model.predict(proc_img)[0][predclass]>0.5):\n                print(model.predict(proc_img)[0][predclass])\n                cv2.putText(roi,str(predclass), (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255))\n        '''\n\n\n\n            cv2.imshow('roi', roi)\n        \n        \n        \n        \n        #Right hand\n        \n            #print (len(xcords))\n    if len(xcords)>=5:\n        KeyPoint = xcords[2]\n        if (xcords[3] < KeyPoint and xcords[4] < KeyPoint):\n            thumbIsOpen = True\n            cv2.putText(img_cpy,\"thumb is open\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n                \n    if len(ycords)>=9:   \n        KeyPoint = ycords[6]\n        if (ycords[7] < KeyPoint and ycords[8] < KeyPoint):\n            firstFingerIsOpen = True\n            cv2.putText(img_cpy,\"firstfinger is open\", (50,80), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n                \n    if len(ycords)>=13:   \n        KeyPoint = ycords[10]\n        if (ycords[11] < KeyPoint and ycords[12] < KeyPoint):\n            secondFingerIsOpen  = True\n            cv2.putText(img_cpy,\"secondfinger is open\", (50,110), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n                \n    if len(ycords)>=17:   \n        KeyPoint = ycords[14]\n        if (ycords[15] < KeyPoint and ycords[16] < KeyPoint):\n            thirdFingerIsOpen  = True\n            cv2.putText(img_cpy,\"thirdfinger is open\", (50,140), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n                \n    if len(ycords)>=21:   \n        KeyPoint = ycords[18]\n        if (ycords[19] < KeyPoint and ycords[20] < KeyPoint):\n            fourthFingerIsOpen  = True\n            cv2.putText(img_cpy,\"fourthfinger is open\", (50,170), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n                \n                \n            \n            \n\n            \n\n\n    \n    \n  cv2.imshow('MediaPipe Hands', img_cpy)\n  \n  cv2.imshow('MediaHands', image)\n  if cv2.waitKey(5) & 0xFF == 27:\n    break\nhands.close()\ncap.release()"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": "cap.release()\ncv2.destroyAllWindows()"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "11"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "5 +(6)"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(158, 128, 3)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "roi.shape"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "penv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
